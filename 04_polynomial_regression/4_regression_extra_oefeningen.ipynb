{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alouwyck/vives-machine-learning/blob/main/04_polynomial_regression/4_regression_extra_oefeningen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lewAFonyBbSW"
      },
      "source": [
        "<img src=\"data:image/png;base64,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\" align=\"right\" /><br>\n",
        "\n",
        "\n",
        "**MACHINE LEARNING FUNDAMENTALS**<br>\n",
        "Academiejaar 2023-2024<br>\n",
        "Andy Louwyck\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "lewAFonyBbSW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lineaire regressie"
      ],
      "metadata": {
        "id": "_WeXDwf6bK4q"
      },
      "id": "_WeXDwf6bK4q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 1"
      ],
      "metadata": {
        "id": "Fhk4DydHigkb"
      },
      "id": "Fhk4DydHigkb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laad de \"Diabetes\" dataset in met de functie `load_diabetes()` uit de `datasets` module van Scikit-Learn. Welke features zijn er?\n",
        "\n",
        "Voer een lineaire regressie uit om het target van de dataset te voorspellen a.d.h.v. het BMI van een patiënt. Wat is de R², de correlatiecoëfficiënt en de MSE? Is er een sterk lineair verband?\n",
        "\n",
        "Maak een scatterplot van de data en voeg de regressielijn toe."
      ],
      "metadata": {
        "id": "Iuzlr5DsbkfM"
      },
      "id": "Iuzlr5DsbkfM"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UjgwRmPYqcjd"
      },
      "id": "UjgwRmPYqcjd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 2"
      ],
      "metadata": {
        "id": "51RGzCdEW5u0"
      },
      "id": "51RGzCdEW5u0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Kaggle](https://www.kaggle.com/) is een online community voor mensen die bezig zijn met data science en machine learning. Je vindt er heel wat interessante datasets terug met bijhorende voorbeeldcode. Kaggle is ook bekend voor de competities die het organiseert.\n",
        "\n",
        "In deze oefening gaan we een eenvoudige dataset downloaden van Kaggle met features van huizen: de oppervlakte, het aantal slaapkamers, de ouderdom van het huis en de prijs. Bedoeling is om een regressiemodel te trainen obv die dataset waarmee we dan de prijs van een nieuw huis kunnen voorspellen. Omdat we hier 3 onafhankelijke variabelen hebben (de features oppervlakte, aantal slaapkamers en de ouderdom) en 1 afhankelijke variabele (de target prijs) spreken we hier van **multivariate lineaire regressie**. Synoniemen zijn multivariabele of meervoudige lineaire regressie."
      ],
      "metadata": {
        "id": "ie3wtqoec5B0"
      },
      "id": "ie3wtqoec5B0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "De dataset vind je hier:\n",
        "\n",
        "https://www.kaggle.com/code/pankeshpatel/ml-for-beginners-2-multivariate-regression/data.\n",
        "\n",
        "Lees de csv-file in en check of er ontbrekende waarden zijn. Je zal merken dat er één waarde ontbreekt bij het aantal slaapkamers. Vul die waarde op met de mediaan van die variabele. Uiteraard maak je hiervoor gebruik van code! Check bijvoorbeeld Pandas methode [`fillna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n",
        "\n",
        "In een volgende stap gaan we na of we effectief lineaire regressie kunnen toepassen op de data. M.a.w. is er een lineair verband tussen de features en de target? We kunnen hiervoor gebruik maken van plot functies uit de [seaborn](https://seaborn.pydata.org/) library die gebaseerd is op matplotlib en speciaal is ontwikkeld voor het creëren van statistische plots.\n",
        "\n",
        "Maak een [`pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn.pairplot) van de data en check of er inderdaad een lineair verband is tussen de prijs en de andere features. Naast een visuele check kunnen we natuurlijk ook de correlatiecoëfficiënt berekenen. Bij een multivariate analyse stellen we hiervoor een correlatiematrix op. Check hiervoor Pandas methode [`corr`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html). Visualiseer de matrix met de [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) functie van `seaborn`."
      ],
      "metadata": {
        "id": "lpbrd84XfwEN"
      },
      "id": "lpbrd84XfwEN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deze eerste fase van het verkennen van de data noemen we de **exploratory data analysis** (EDA). Als je de correlatiematrix correct hebt opgesteld, dan stel je vast dat er effectief een lineair verband is tussen features en targets. Dus je kan nu lineaire regressie toepassen mbv de `LinearRegression` klasse van `sklearn`. Dit is uiteraard de **trainingsfase**. Bereken de R² score en de Mean Absolute Error (MAE) om het bekomen model te evalueren.\n",
        "\n",
        "Eens het model is getraind en geëvalueerd, komen we in de **inferentiefase** waarin we voorspellingen gaan maken met nieuwe data. Doe dit hier voor een huis dat 5 jaar oud is, 8 slaapkamers heeft en met een oppervlakte van 5000. Hoeveel schat je dat de kostprijs van dat huis is?"
      ],
      "metadata": {
        "id": "F1U-4ZaFhW8b"
      },
      "id": "F1U-4ZaFhW8b"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qj4-MK3Y3fUI"
      },
      "id": "qj4-MK3Y3fUI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 3"
      ],
      "metadata": {
        "id": "eZthAYVYpbjE"
      },
      "id": "eZthAYVYpbjE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We kunnen zelf datasets creëren voor lineaire regressie door gebruik te maken van de functie [`make_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression) uit de `sklearn.datasets` module.\n",
        "\n",
        "Als voorbeeld genereren we hier een dataset met 10 samples voor enkelvoudige lineaire regressie. Dat is dus een dataset die uit 1 feature `x` en 1 target `y` bestaat. We voegen een `bias` toe van -3, wat een ander woord is voor intercept, en `noise` met een standaardafwijking van 20.\n",
        "\n",
        "Merk op dat we hier ook het aantal 'informatieve' features moeten opgeven. Dat zijn features die effectief correleren met de target. In dit geval hebben we dus 1 informatieve feature.\n",
        "\n",
        "We fitten de dataset mbv de `LinearRegression` klasse van module `sklearn.linear_model`, berekenen de R²-score, en maken tenslotte een plot van de dataset mét de regressielijn mbv basic pyplot functies en mbv functie [`lmplot`](https://seaborn.pydata.org/generated/seaborn.lmplot.html#seaborn.lmplot) van `seaborn`."
      ],
      "metadata": {
        "id": "6CukcFYmpeNW"
      },
      "id": "6CukcFYmpeNW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esU4Z94Q3ksq"
      },
      "id": "esU4Z94Q3ksq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 4"
      ],
      "metadata": {
        "id": "jkELpNOwvKnb"
      },
      "id": "jkELpNOwvKnb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We maken opnieuw gebruik van de functie `make_regression` om een dataset te genereren voor multivariate lineaire regressie. We nemen 1000 samples, 10 features waarvan 5 informatieve, 1 target, een bias van 15, en voegen noise toe met een standaarddeviatie van 50.\n",
        "\n",
        "We stoppen de features en de target in een Pandas DataFrame. Op die manier kunnen we de belangrijkste statistieken opvragen mbv methode `describe`. We kunnen zo ook snel de correlatiematrix berekenen en zien dat er inderdaad maar 5 van de 10 features correleren met de target. Tenslotte fitten we de dataset mbv een lineair regressiemodel en we berekenen de R²-score, de MAE en de MSE om het model te evalueren."
      ],
      "metadata": {
        "id": "1DqIwHIcvMUx"
      },
      "id": "1DqIwHIcvMUx"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jb-9SEmo3qkX"
      },
      "id": "jb-9SEmo3qkX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "radio-edgar",
      "metadata": {
        "id": "radio-edgar"
      },
      "source": [
        "# Polynomiale regressie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfeBUm0P37i3"
      },
      "source": [
        "## Opdracht 5"
      ],
      "id": "RfeBUm0P37i3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stretch-frontier"
      },
      "source": [
        "We willen polynomiale regressie uittesten en daarvoor gaan we een fictieve dataset maken adhv een veeltermfunctie waarvan we de vergelijking kennen:\n",
        "\n",
        "> $y = -x^2 + x + 15$\n",
        "\n",
        "We schrijven zelf een functie om `y`-waarden te berekenen obv gegeven `x`-waarden. Op die manier zorgen we ervoor dat onze code herbruikbaar is! We maken gebruik van de volgende functiedefinitie\n",
        "\n",
        "```\n",
        "def polynomial(coefs, x):\n",
        "```\n",
        "We testen onze functie door waarden te genereren voor `x` tussen -5 en 5. We kunnen daarvoor gebruik maken van functie `np.linspace`"
      ],
      "id": "stretch-frontier"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAI4xP4NqfZZ"
      },
      "id": "FAI4xP4NqfZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incident-telling"
      },
      "source": [
        "We plotten nu die punten op een grafiek en definiëren opnieuw een functie:\n",
        "```\n",
        "def draw_polynomial(coefs, x):\n",
        "```"
      ],
      "id": "incident-telling"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XxHkLiMYqhLD"
      },
      "id": "XxHkLiMYqhLD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypNmcbaJ4H7o"
      },
      "source": [
        "Nu gaan we rond die kwadratische curve een puntenwolk genereren. We genereren X-waarden in het interval $[-5,5]$. Voor de punten op de Y-as gebruiken we de veeltermfunctie en we voegen er **ruis** (Engels: noise) aan toe mbv de volgende formule:\n",
        "```\n",
        "polynomial(coefs, x) + random.gauss(mu=0, sigma=1.5)\n",
        "```\n",
        "\n",
        "Functie `random.gauss` genereert een random getal dat een normaalverdeling volgt met gemiddelde `mu` en standaardafwijking `sigma`.\n",
        "\n",
        "We genereren 10 punten en slaan de coördinaten op in een lijst genaamd X en Y, respectievelijk."
      ],
      "id": "ypNmcbaJ4H7o"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OS6yb_kvqjLx"
      },
      "id": "OS6yb_kvqjLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9mY3EOz4POb"
      },
      "source": [
        "We visualiseren de gegenereerde datapunten op een scatterplot."
      ],
      "id": "I9mY3EOz4POb"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GF4EJcDRqkc5"
      },
      "id": "GF4EJcDRqkc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0F-gcA_4Tj1"
      },
      "source": [
        "## Opdracht 6"
      ],
      "id": "o0F-gcA_4Tj1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9SmxjmO4Tj2"
      },
      "source": [
        "Op de puntenwolk die we gegenereerd hebben, proberen we nu verschillende modellen uit. Eerst stoppen we de punten in een dataframe, en sorteren we de gegenereerde datapunten volgens de X-as."
      ],
      "id": "l9SmxjmO4Tj2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-ZvlDbkqqLC"
      },
      "id": "d-ZvlDbkqqLC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHDGC1U4Z62"
      },
      "source": [
        "We visualiseren de datapunten in het dataframe nogmaals adhv een scatterplot om te controleren of de conversie naar een dataframe en de sortering gelukt zijn."
      ],
      "id": "MGHDGC1U4Z62"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H2Me8mcTqrZO"
      },
      "id": "H2Me8mcTqrZO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKbMp1Xs4fB_"
      },
      "source": [
        "In de volgende code tonen we hoe we polynomiale regressie kunnen toepassen met behulp van SciKit-Learn. We proberen 4 modellen uit: een lineair model, en drie polynomiale modellen van graad 2, 5 en 10.\n",
        "We plaatsen die plots naast elkaar en printen per plot ook de MSE.\n",
        "Een dergelijke plot kan gebruikt worden als een visuele inspectie van verschillende modellen.\n",
        "Om overfitting te evalueren wordt gebruik gemaakt van cross validation. We reserveren dus herhaaldelijk een stukje van de trainingset als validatieset."
      ],
      "id": "eKbMp1Xs4fB_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "h0Zhixk5597t"
      },
      "id": "h0Zhixk5597t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "natural-centre",
      "metadata": {
        "scrolled": true,
        "id": "natural-centre"
      },
      "outputs": [],
      "source": [
        "degrees = [1, 2, 5, 10]\n",
        "\n",
        "# feature en label selecteren uit dataframe \"data\"\n",
        "X_train = data['x'].to_numpy()\n",
        "y_train = data['y'].to_numpy()\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "for i in range(len(degrees)):\n",
        "\n",
        "    ax = plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.setp(ax, xticks=(), yticks=())\n",
        "\n",
        "    # Make pipeline for polynomial regression and fit data\n",
        "    polynomial_features = PolynomialFeatures(\n",
        "        degree=degrees[i],\n",
        "        include_bias=False  # op False zetten want intercept/bias zit ook in LinearRegression!\n",
        "    )\n",
        "    linear_regression = LinearRegression()\n",
        "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                         (\"linear_regression\", linear_regression)])\n",
        "    pipeline.fit(X_train[:, np.newaxis], y_train)  # X moet 2D matrix zijn!\n",
        "\n",
        "    # Validate the models using crossvalidation\n",
        "    scores = cross_val_score(pipeline, X_train[:, np.newaxis], y_train,\n",
        "                             scoring=\"neg_mean_squared_error\",  # neg_mean_squared error = -MSE\n",
        "                             cv=10)  # cv is het aantal folds\n",
        "\n",
        "    # Regression curve\n",
        "    X_curve = np.linspace(-5, 5, 100)\n",
        "    Y_curve = pipeline.predict(X_curve[:, np.newaxis])\n",
        "    Y_true = polynomial(coefs, X_curve)  # oorspronkelijke model\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(X_curve, Y_curve, label=\"Model\")\n",
        "    plt.plot(X_curve, Y_true, label=\"True function\")\n",
        "    plt.scatter(X_train, y_train, edgecolor='b', s=20, label=\"Samples\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.xlim((-5, 5))\n",
        "    plt.ylim((-20, 20))\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dutch-proportion",
      "metadata": {
        "id": "dutch-proportion"
      },
      "source": [
        "# Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEvikKwa4qnF"
      },
      "source": [
        "## Opdracht 7"
      ],
      "id": "wEvikKwa4qnF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSBbGPD04qnG"
      },
      "source": [
        "We gaan nu polynomiale regressie mét regularisatie toepassen op de dataset die we hebben gegenereerd. We gebruiken een veelterm van graad 10. Eerst voeren we de regressie uit zonder regularisatie zodat we goed het effect ervan kunnen zien.\n",
        "\n",
        "We baseren ons op de code van hierboven, maar passen deze keer geen crossvalidatie toe. We plotten het resultaat op een figuur en zorgen ervoor dat de figuur zowel de originele veeltermfunctie, de datawolk, als de regressiecurve afbeeldt."
      ],
      "id": "VSBbGPD04qnG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6ujR-MnrEl8"
      },
      "id": "E6ujR-MnrEl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_4XxCel40Rc"
      },
      "source": [
        "We doen nu net hetzelfde maar deze keer passen we **Ridge regressie** toe. We gebruiken hiervoor de volgende code:\n",
        "\n",
        "> `polyreg=make_pipeline(PolynomialFeatures(degree, include_bias=False), Ridge(alpha=0.1, tol=0.1))`"
      ],
      "id": "C_4XxCel40Rc"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxxdmpWjrGZf"
      },
      "id": "VxxdmpWjrGZf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtz7Qujr44P9"
      },
      "source": [
        "Tenslotte passen we ook **Lasso regressie** toe. Hiervoor gebruiken we de volgende code:\n",
        "\n",
        "> `polyreg=make_pipeline(PolynomialFeatures(degree, include_bias=False), Lasso(alpha=0.1, tol=0.1))`"
      ],
      "id": "Wtz7Qujr44P9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-WAktvAIrJOr"
      },
      "id": "-WAktvAIrJOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training, validating, testing"
      ],
      "metadata": {
        "id": "lpPUCv7e-i41"
      },
      "id": "lpPUCv7e-i41"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 8"
      ],
      "metadata": {
        "id": "_1tCFoLb-oED"
      },
      "id": "_1tCFoLb-oED"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBkT3WGzltRa"
      },
      "source": [
        "In deze opdracht illustreren we de volledige trainingfase met **simple hold-out validation**. We testen ook het geselecteerde model, en we doen een finale training op de volledige dataset om zo tot ons definitieve model te komen.\n",
        "\n",
        "Lees de dataset \"LinkedIn.csv\" in als Pandas dataframe.\n",
        "\n",
        "Splits je dataset als volgt op: neem telkens 500 willekeurige datapunten voor validatie- en testset; de overige datapunten vormen de trainingset. Tip: check scikit-learn functie `train_test_split`.\n",
        "\n",
        "Pas enkelvoudige lineaire regressie en 2-de graads polynomiale regressie toe op de trainingset. Bereken telkens de MSE voor training- en validatieset. Voor welk model kies je?\n",
        "\n",
        "Evalueer het gekozen model met de testset. Krijg je een even goed resultaat? Indien ja, train je definitieve model op de volledige set."
      ],
      "id": "MBkT3WGzltRa"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sVCnoFHrP9W"
      },
      "id": "2sVCnoFHrP9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opdracht 9"
      ],
      "metadata": {
        "id": "7OAp2GQ1iVZR"
      },
      "id": "7OAp2GQ1iVZR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw_9Hxb4iSiI"
      },
      "source": [
        "In deze opdracht illustreren we de volledige trainingfase met **K-fold crossvalidatie**. We testen ook het geselecteerde model, en we doen een finale training op de volledige dataset om zo tot ons definitieve model te komen.\n",
        "\n",
        "Lees de dataset \"LinkedIn.csv\" in als Pandas dataframe.\n",
        "\n",
        "Splits je dataset als volgt op: neem 500 willekeurige datapunten voor de testset; de overige datapunten vormen de trainingset. Tip: check scikit-learn functie `train_test_split`.\n",
        "\n",
        "Pas enkelvoudige lineaire regressie en 2-de graads polynomiale regressie toe op de trainingset. Pas K-fold crossvalidatie toe met 15 folds. Tip: check scikit-learn functie `cross_validate`. Bereken voor beiden de gemiddelde MSE voor training en validatie. Voor welk model kies je?\n",
        "\n",
        "Hertrain het gekozen model op de volledige trainingset en evalueer met de testset. Krijg je een even goed resultaat? Indien ja, train je definitieve model op de volledige dataset."
      ],
      "id": "lw_9Hxb4iSiI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mci9f8NFrZrJ"
      },
      "id": "Mci9f8NFrZrJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}